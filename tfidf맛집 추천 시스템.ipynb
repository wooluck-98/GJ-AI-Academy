{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 수원역\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nK1vIhkDdgp8', 'cW8c9YDYkK9N', 'NqYakN0JYWOB', 'EEgchLv8wmXY', 'tTZ6e6QdnifX', 'odtj0fYHmQuq', '3QlBuSnnhog4', 'JxtQheaw1y3E', 'yiXPKpS7xYuu', 'q3gNXHRayoqG', 'Ieh7s0kC9SUk', 'FFEKN2MuiEM0', 'd5jG04QGJIXF', '8xiYHTWf8bVl', 'B0X0U8xl6Oqa', 'rKk3F0b1OuFQ', 'KbC6jVtA7m9s', 'gBnvHRtsdQjK', 'Jes2YIknncoW', 'nSojt9uOADot', '0roQ0CdIqeKn', 'Sjcup6rNX3MQ', 'lw9ArxMysTYk', 'aEizA3a5SZsa', '2IjDoSkprAVQ', 'P2LcklUoI4iy', 'vZemCxouiNgY', 'qGnDdu2F1JrO', 'O5gCN9O7q4Gu', 'FiznRzIRjlLW', 'SGMKG2EdIWM0', 'dCEVnwNm9YvQ', 'G3sGcAh9oYvK', 'LOAzxHUA20ev', 'iFl3bPnUAI9P', 'E01WdAe0zfOp', 'HvDJB1UWdJSh', '4tnD1r6mVDsu', 'pyPXQmVXm8UF', 'FpEQGriaMIhN', 'sCV1IkCZtSPw', 'pIkvkUzWayEY', 'HboXZPegwNFg', 'kgtuufD8CCLT', 'lZsNI9t18L7G', 'Od36MvnLgeox', '0TgivygeXj8q', 'lUkBQOfjPOCV', 'ij7QIYuQXHzH', 'rI0ksYWnSJqQ', 'TwYzR4mxVdQ9', 'ymDDfki9U3oq', 'mYnrRh6VIACv', 'vypcf7KlTi5w', 'RxMKbJPjOlIh', 'nX89S2nnCbMR', 'jVLkloOoVqPG', 'dlnY7S4WScIU', 't2lpB58Gvl6q', 'EhiCcQbaKnmM', 'Wp3r2I7Fadwz', 'uqkRLV9SvXdO', '83eeLOwTCknO', 'TWsFp7BVAnMj', 'zqqItufBYbzZ', 'Dcm3OxDq9gdN', 'fwazN5wo8GZS', 'QeTlXRZNMJd0', 'QJFfS2pS8sbn', 'o70fqppOdp3j', 'Cb6viZyaEIVC', 'YWPAvNV6tEVr', 'wRJYjyfVMlYf', 'uciSoWAjLFb6', 'd6VQTp4WYVWQ', '6gpHnLzeRSUG', 'xn6KwxDCPlgh', 'a3mtac0Kkioi', 'Z1RlUeqk05Gh', 'nmHfsLD1sB8k', 'MtNUpVvVoKls', 'heg8L4fqpHlt', 'XEUiaT26jrfK', 'PBjKSQCWH17Y', 'xYUyJ6Ki5zDB', 'OWQgcnygYqe7', 'fMGrbJYi2mbm', 'pf2IzB2Lbxv9', 'eRL122acgEXi', 'mWikQxvwMQy3', 'tZUJVxKIgOWE', 'OQVZo0TSLeh2', 'vSO4MwtwSYJI', '2f9wiy42eqws', 'M2wjiKy6oBqb', '5u1Jo2U4b4Aa', 'N123LoflncnP', 'QPnOzTJUUxfD', 'deliH1TT3TSv', 'ZKwhLsHTUWxa']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "search_input = input()\n",
    "hrefs = []\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36',\n",
    "}\n",
    "url = 'https://www.diningcode.com/list.php?query=' + search_input\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "stores = soup.find_all(\"a\", class_=\"blink\")\n",
    "for store in stores:\n",
    "    hrefs.append(store['href'].split('rid=')[-1])\n",
    "for page in range(2,11):\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36',\n",
    "   }\n",
    "    data = {\n",
    "    'type': '',\n",
    "    'query': search_input,\n",
    "    'lat': '',\n",
    "    'lng': '',\n",
    "    'dis': '',\n",
    "    'page': str(page),\n",
    "    'chunk': '10',\n",
    "    'rn': ''\n",
    "    }\n",
    "    response = requests.post('https://www.diningcode.com/2018/ajax/list.php', headers=headers, data=data)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    stores = soup.find_all(\"a\", class_=\"blink\")\n",
    "    for store in stores:\n",
    "        hrefs.append(store['href'].split('rid=')[-1])\n",
    "print(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name                                                Tag  \\\n",
      "0              아다미식당  점심식사 점심식사 점심식사 점심식사 점심식사 점심식사 점심식사 점심식사 혼밥 혼밥 ...   \n",
      "1              닝교초식당  점심식사 점심식사 점심식사 점심식사 저녁식사 저녁식사 저녁식사 혼밥 혼밥 혼밥 데이...   \n",
      "2              이가꽈배기                                                      \n",
      "3                훌리오                          저녁식사 이국적/이색적 이국적/이색적 조용한    \n",
      "4            브리오슈 도레        간식 점심식사 시끌벅적한 시끌벅적한 시끌벅적한 깔끔한 예쁜 서민적인 캐주얼한    \n",
      "..               ...                                                ...   \n",
      "96               르레브                                     서민적인 조용한 캐주얼한    \n",
      "97         탐앤탐스 수원역점                                    가성비좋은 캐주얼한 깔끔한    \n",
      "98            BHC 치킨                          저녁식사 술모임 캐주얼한 캐주얼한 시끌벅적한    \n",
      "99   그래인스쿠키 AK플라자수원점                                          예쁜 고급스러운    \n",
      "100              수원역  점심식사 점심식사 점심식사 점심식사 점심식사 점심식사 점심식사 점심식사 점심식사 점...   \n",
      "\n",
      "                detail  \n",
      "0     수원역 | 순대국   따로국밥  \n",
      "1       수원역 | 돈부리   벤또  \n",
      "2       수원역 | 꽈배기   전병  \n",
      "3    수원역 | 멕시칸요리   멕시코  \n",
      "4        수원 | 브런치   카페  \n",
      "..                 ...  \n",
      "96       수원역 | 커피   카페  \n",
      "97            수원역 | 카페  \n",
      "98       수원역 | 커리   치킨  \n",
      "99            수원역 | 쿠키  \n",
      "100            details  \n",
      "\n",
      "[101 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "keyword_list = ['배달', '아침식사', '점심식사', '저녁식사', '식사모임', '술모임', '혼밥',\n",
    "                '혼술', '회식', '데이트', '기념일', '가족외식', '간식', '숨은맛집',\n",
    "                '서민적인', '캐주얼한', '고급스러운', '격식있는', '가성비좋은', '푸짐한',\n",
    "                '조용한', '시끌벅적한', '예쁜', '깔끔한', '이국적/이색적',\n",
    "                '경관/야경이좋은', '지역주민이찾는']\n",
    "conv_list = ['무료주차','발렛주차','주차불가','개별룸','대형룸','24시간영업','야외좌석(테라스)','놀이방','애완동물동반','콜키지무료']\n",
    "purpose_list = ['아침식사','점심식사','저녁식사','식사모임','가족외식','배달','아이동반','다이어트식당',\n",
    "                '실버푸드','술모임','차모임','혼카페','혼밥','혼술','접대','회식','데이트','기념일','간식']\n",
    "\n",
    "keyword_dict = {}\n",
    "\n",
    "front_url = 'https://www.diningcode.com/profile.php?rid='\n",
    "headers2 = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36',\n",
    "}\n",
    "f = open('res_data.csv', 'w')\n",
    "f.write('Name,Tag,detail\\n')\n",
    "tot_str=''\n",
    "for code in hrefs:\n",
    "    res_url = front_url + code\n",
    "    response = requests.post(res_url, headers=headers2)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    res_name = soup.find('div',class_='tit-point').get_text().replace('\\n', '')\n",
    "#     print(res_name)\n",
    "    tag_list=[]\n",
    "    for tag in soup.find_all('p',class_= 'icon'):\n",
    "        tag_list.append(tag.get_text())\n",
    "    tags_str=''\n",
    "    for tags in tag_list:\n",
    "        tags = tags.split('(')\n",
    "        tag_name = tags[0]\n",
    "        tag_freq = tags[-1][0:-1]\n",
    "        if tag_name in purpose_list:\n",
    "            tag_freq = int(tag_freq) * 0.6\n",
    "        if tag_name in conv_list:\n",
    "            tag_freq = 0\n",
    "        if tag_name not in keyword_dict.keys():\n",
    "            keyword_dict[tag_name] = 5\n",
    "        else:\n",
    "            keyword_dict[tag_name] = keyword_dict[tag_name] + int(tag_freq)\n",
    "        if tag_name in keyword_list:\n",
    "            tags_str += (tag_name+' ')*int(tag_freq)\n",
    "            tot_str += tags_str\n",
    "    detail = soup.find('div',class_='s-list pic-grade').find('div',class_='btxt').get_text().strip().replace(',',' ')\n",
    "    f.write(res_name+','+tags_str+','+detail+'\\n')\n",
    "f.write(search_input+','+tot_str+','+'details''\\n')\n",
    "f.close()\n",
    "df_ori = pd.read_csv('res_data.csv',encoding='cp949')\n",
    "df_ori = df_ori.fillna(' ')\n",
    "print(df_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f9c739c0a57a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstylecloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import image\n",
    "import PIL\n",
    "import stylecloud\n",
    "\n",
    "print(keyword_dict)\n",
    "a=stylecloud.gen_stylecloud(text=keyword_dict, icon_name = \"fas fa-fish\", background_color=\"black\",font_path='C:/Windows/Fonts/malgun.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name                detail\n",
      "100              구월동               details\n",
      "12               유타로     구월동 | 오코노미야키   라멘\n",
      "2           마초쉐프 구월점     구월동 | 스텔라피자   파스타\n",
      "1             파니노구스토      구월동 | 화덕피자   파스타\n",
      "0              비스트로J     구월동 | 시금치피자   파스타\n",
      "21               차이홍    구월동 | 차돌박이짬뽕   중국집\n",
      "23          탕화쿵푸 마라탕           인천구월동 | 마라탕\n",
      "24              그라나다         구월동 | 감바스   펍\n",
      "30   홍콩반점 0410 인천구월점      구월동 | 찹쌀탕수육   짬뽕\n",
      "5            곰설채 설렁탕     구월동 | 설렁탕   돌솥설렁탕\n",
      "27              구월오리      구월동 | 오리고기   주물럭\n",
      "6               겐키라멘       구월동 | 라멘   차슈덮밥\n",
      "10           보통날의파스타       구월동 | 파스타   리조또\n",
      "16       등촌샤브칼국수 구월점  인천구월동 | 샤브샤브   버섯매운탕\n",
      "63        마호가니 인천구월점       구월동 | 콜드브루   카페\n",
      "11          홍춘천치즈닭갈비        구월동 | 알쌈   닭갈비\n",
      "67        니뽕내뽕 인천구월점       구월동 | 퓨전짬뽕   짬뽕\n",
      "7               사곶냉면        구월동 | 까나리   냉면\n",
      "14              봉추찜닭        구월동 | 찜닭   누룽지\n",
      "13               은행골       구월동 | 초밥   참치전문\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tfidf_matrix = tfidf_vec.fit_transform(df_ori['Tag'])\n",
    "tags_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "similar_index = np.argsort(-tags_similarity)\n",
    "count_vec = CountVectorizer(ngram_range=(1, 2))\n",
    "count_matrix = count_vec.fit_transform(df_ori['Tag'])\n",
    "tags_similarity = cosine_similarity(count_matrix, count_matrix)\n",
    "similar_index = np.argsort(-tags_similarity)\n",
    "res_index = df_ori[df_ori['Name']==search_input].index.values\n",
    "similar_res = similar_index[res_index, :20]\n",
    "similar_res_index = similar_res.reshape(-1)\n",
    "\n",
    "print(df_ori.iloc[similar_res_index][['Name','detail']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
